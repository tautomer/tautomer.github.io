{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting \"protein-protein interactions\" with neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: building the network\n",
    "\n",
    "This is the second part of the post. For part one, please refer to \n",
    "[this post](/post/posts/protein_protein_interaction/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have all the datasets sorted out, the next step in to build the\n",
    "network. The design of the network is really simple. I am using one CNN to\n",
    "process one sequence, and then concatenate the two networks together and output\n",
    "the classification results with a DNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure we run the model on the right device, we first determine the best\n",
    "device to use for different platforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # with Nvidia GPU\n",
    "    device = \"cuda\"\n",
    "elif torch.has_mps:\n",
    "    # on Apple Silicon\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    # on CPU\n",
    "    device = \"cpu\"\n",
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let us build the network. I will use 1D CCN here, use the sequences as the\n",
    "channels. I do not know why, but in my test, this works better than using amino\n",
    "acid types as channels for 1D CNN or using the sequence and amino acid types for\n",
    "2D CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I will encode the whole sequence with a one-hot encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPIEncoder(torch.nn.Module):\n",
    "    def __init__(self, one_hot_classes):\n",
    "        self.one_hot_classes = one_hot_classes\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x: torch.tensor):\n",
    "        return torch.nn.functional.one_hot(\n",
    "            x.long(), num_classes=self.one_hot_classes\n",
    "        ).type(torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will build the actual network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPICNN(torch.nn.Module):\n",
    "    def __init__(self, one_hot_classes, output_classes, input_channels=1):\n",
    "        super().__init__()\n",
    "        self.cnn1 = torch.nn.Sequential(\n",
    "            PPIEncoder(one_hot_classes),\n",
    "            # 1st CNN layer\n",
    "            torch.nn.Conv1d(\n",
    "                in_channels=input_channels, out_channels=8, kernel_size=7\n",
    "            ),\n",
    "            torch.nn.BatchNorm1d(8),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.2),\n",
    "            # 2st CNN layer\n",
    "            torch.nn.Conv1d(in_channels=8, out_channels=10, kernel_size=3),\n",
    "            torch.nn.BatchNorm1d(10),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.2),\n",
    "            torch.nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            # 3rd CNN layer\n",
    "            torch.nn.Conv1d(in_channels=10, out_channels=3, kernel_size=3),\n",
    "            torch.nn.BatchNorm1d(3),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.2),\n",
    "            # 4th CNN layer\n",
    "            torch.nn.Conv1d(in_channels=3, out_channels=3, kernel_size=3),\n",
    "            torch.nn.BatchNorm1d(3),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.2),\n",
    "            torch.nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.cnn2 = deepcopy(self.cnn1)\n",
    "\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(2316, 80),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(),\n",
    "            torch.nn.Linear(80, 40),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(),\n",
    "            torch.nn.Linear(40, output_classes),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, protein1: torch.Tensor, protein2: torch.Tensor):\n",
    "        protein1 = self.cnn1(protein1)\n",
    "        protein2 = self.cnn2(protein2)\n",
    "        combined = torch.cat((protein1, protein2), dim=1).flatten(1)\n",
    "        return self.fc(combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will process each protein sequence with a 4-layer 1D CNN. Batch\n",
    "normalization, pooling, dropout, and activation functions are all hyperparameter\n",
    "you can play with. We set up `cnn1` and get an identical copy for the other\n",
    "sequence call `cnn2`. Then we concatenate the two networks together and flatten\n",
    "the resulting tensor to 1D and feed it into a 3-layer fully-connected network.\n",
    "Sine this is a binary classification problem, we use a `Sigmoid` function at the\n",
    "end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fairly simple, right? In fact, with such a simple set up, we can already achieve\n",
    "98%+ accuracy. In the next chapter, I will show how I trained this network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
